{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArMpljpxfZeJ"
      },
      "source": [
        "### Install dependencies\n",
        "* You're likely to be asked to restart the runtime if using colab, then do it!  \n",
        "* Ignore the warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "m_e0y1gQbdcQ",
        "outputId": "d19f13e3-479a-425e-d0ed-6392574c1126"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install supabase\n",
        "!pip install lenskit==0.14.4\n",
        "# !pip install numpy==1.26\n",
        "!pip install python-dotenv\n",
        "# !pip install pandas==2.1.4\n",
        "\n",
        "!pip install numpy==1.24.3\n",
        "!pip install pandas==1.5.3\n",
        "# error solver:\n",
        "# !pip install --force-reinstall numpy==1.24.3 pandas==1.5.3 scikit-learn lenskit==0.14.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tuqey6o9e5oy",
        "outputId": "0ef57fdd-86c9-4255-db0f-8fe6d8189e2c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.14.4'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Just for debug purpose\n",
        "import lenskit\n",
        "lenskit.__version__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8ZFigTVfvAw"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7V9SiI3dy-o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "from lenskit.algorithms import Recommender\n",
        "from lenskit.algorithms.basic import Bias\n",
        "from lenskit import batch, topn, util\n",
        "from lenskit import crossfold as xf\n",
        "from typing import List, Dict, Any\n",
        "import supabase\n",
        "import os\n",
        "from dotenv import load_dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2RlIXPfgY2Z"
      },
      "source": [
        "### Set up the secret\n",
        "Put your Supabase **url** along with **API Key** in a file, and name it `.env`  \n",
        "The file content should look like this:  \n",
        "```\n",
        "SUPABASE_KEY=<Your Supabase API Key>\n",
        "SUPABASE_URL=<Your Supabase url>\n",
        "```\n",
        "\n",
        "Then place the `.evn` file under the same directory with this notebook\n",
        "\n",
        "---\n",
        "\n",
        "#### Now go executing the next block!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DUxUav1dfwH",
        "outputId": "7bbc3cec-b283-402a-d3f4-c5e876cf074f"
      },
      "outputs": [],
      "source": [
        "# load the file you set up earlier and dump it into environment\n",
        "load_dotenv()\n",
        "\n",
        "# retrieve the url and API key from environment and assign them to variables\n",
        "supabase_url = os.environ.get('SUPABASE_URL')\n",
        "supabase_key = os.environ.get('SUPABASE_KEY')\n",
        "\n",
        "# check whether the setup goes smoothly\n",
        "if supabase_key:\n",
        "    print('Supabase key loaded successfully.')\n",
        "else:\n",
        "    print(\"Supabase key not found. Please make sure it's defined as a secret.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUpqgv_Mdr_-"
      },
      "outputs": [],
      "source": [
        "# connect to supabase\n",
        "supabase_client = supabase.create_client(supabase_url, supabase_key)\n",
        "# get all jobs from supabase\n",
        "jobs_data = supabase_client.from_('jobs').select('*').execute().data\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "jobs_df = pd.DataFrame(jobs_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "039p-i2PdnIA"
      },
      "outputs": [],
      "source": [
        "# setting up customised recommender\n",
        "class ContentBasedJobRecommender(Recommender):\n",
        "    '''\n",
        "    Content-based job recommender using TF-IDF and cosine similarity\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.jobs_df = None\n",
        "        self.tfidf_matrix = None\n",
        "        self.feature_columns = [\n",
        "            'job_industry',\n",
        "            'industry',\n",
        "            'primary_category',\n",
        "            'job_title',\n",
        "            'job_name',\n",
        "            'job_description',\n",
        "            'job_category',\n",
        "            'location',\n",
        "            'skills',\n",
        "            'tools'\n",
        "        ]\n",
        "\n",
        "        # Fields for applicant data analysis\n",
        "        self.applicant_fields = [\n",
        "            'apply_education',\n",
        "            'apply_gender',\n",
        "            'apply_language',\n",
        "            'apply_age_distribution',\n",
        "            'apply_experience',\n",
        "            'apply_major',\n",
        "            'apply_skills',\n",
        "            'apply_certificates'\n",
        "        ]\n",
        "        self.id_col = 'job_id'\n",
        "        self.bias = Bias()\n",
        "\n",
        "    def fit(self, jobs_df):\n",
        "        '''\n",
        "        Train the recommender on the provided jobs dataframe\n",
        "        '''\n",
        "        self.jobs_df = jobs_df.copy()\n",
        "\n",
        "        # Create a combined text field for TF-IDF\n",
        "        self.jobs_df['combined_features'] = self.jobs_df.apply(self._combine_features, axis = 1)\n",
        "\n",
        "        # Create TF-IDF matrix\n",
        "        tfidf = TfidfVectorizer(stop_words = 'english')\n",
        "        self.tfidf_matrix = tfidf.fit_transform(self.jobs_df['combined_features'].fillna(''))\n",
        "\n",
        "        # Store cosine similarity matrix for faster recommendations\n",
        "        self.cosine_sim = cosine_similarity(self.tfidf_matrix, self.tfidf_matrix)\n",
        "\n",
        "        # Create a dummy ratings DataFrame for Bias fitting\n",
        "        ratings_data = {\n",
        "            'user': ['dummy_user'] * len(self.jobs_df),\n",
        "            'item': self.jobs_df[self.id_col].tolist(),\n",
        "            'rating': [1.0] * len(self.jobs_df)\n",
        "        }\n",
        "        ratings_df = pd.DataFrame(ratings_data)\n",
        "        self.bias.fit(ratings_df)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _combine_features(self, row):\n",
        "        '''\n",
        "        Combine relevant features into a single string for text processing\n",
        "        '''\n",
        "        combined = ''\n",
        "\n",
        "        # Process regular text fields\n",
        "        for col in self.feature_columns:\n",
        "            if col in row.index and pd.notna(row[col]):\n",
        "                if isinstance(row[col], str):\n",
        "                    combined += row[col] + ' '\n",
        "\n",
        "        # Process benefits fields (they may be empty)\n",
        "        if 'legal_benefits' in row.index and pd.notna(row['legal_benefits']):\n",
        "            combined += row['legal_benefits'] + ' '\n",
        "\n",
        "        if 'other_benefits' in row.index and pd.notna(row['other_benefits']):\n",
        "            combined += row['other_benefits'] + ' '\n",
        "\n",
        "        # Process applicant data fields to understand job requirements\n",
        "        for field in self.applicant_fields:\n",
        "            if field in row.index and pd.notna(row[field]):\n",
        "                try:\n",
        "                    # Try to parse JSON data\n",
        "                    if isinstance(row[field], str):\n",
        "                        data = json.loads(row[field])\n",
        "                    else:\n",
        "                        data = row[field]\n",
        "\n",
        "                    if isinstance(data, dict):\n",
        "                        # Extract all keys and values from the dictionary\n",
        "                        for key, value in data.items():\n",
        "                            combined += f'{key} {value} '\n",
        "                except:\n",
        "                    # If parsing fails, just use as is\n",
        "                    if isinstance(row[field], str):\n",
        "                        combined += row[field] + ' '\n",
        "\n",
        "        return combined\n",
        "\n",
        "    def get_similar_jobs(self, job_id, n = 10):\n",
        "        '''\n",
        "        Get n most similar jobs to the given job_id\n",
        "        '''\n",
        "        if self.jobs_df is None or self.tfidf_matrix is None:\n",
        "            raise ValueError('Recommender has not been trained yet')\n",
        "\n",
        "        # Find the index of the job in our dataframe\n",
        "        idx = self.jobs_df.index[self.jobs_df[self.id_col] == job_id].tolist()\n",
        "        if not idx:\n",
        "            return []\n",
        "        idx = idx[0]\n",
        "\n",
        "        # Get similarity scores\n",
        "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse = True)\n",
        "\n",
        "        # Remove the job itself\n",
        "        sim_scores = [s for s in sim_scores if s[0] != idx]\n",
        "\n",
        "        # Get top N similar jobs\n",
        "        sim_scores = sim_scores[:n]\n",
        "        job_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "        # Return the similar jobs with their similarity scores\n",
        "        result = []\n",
        "        for i, score in enumerate(sim_scores):\n",
        "            job_idx = job_indices[i]\n",
        "            job_data = self.jobs_df.iloc[job_idx].to_dict()\n",
        "            job_data['similarity_score'] = score[1]\n",
        "            result.append(job_data)\n",
        "\n",
        "        return result\n",
        "\n",
        "    # candidates: recommend jobs from given options\n",
        "    # ratings: applicant might rate some jobs in the past\n",
        "    def recommend(self, user_id, n = 10, candidates = None, ratings = None):\n",
        "        '''\n",
        "        Recommend jobs to a user based on their application history (implements the LensKit Recommender interface)\n",
        "        '''\n",
        "        if self.jobs_df is None or self.tfidf_matrix is None:\n",
        "            raise ValueError('Recommender has not been trained yet')\n",
        "\n",
        "        # Find jobs this user has applied to (to avoid repetitive recommendation)\n",
        "        if ratings is not None and not ratings.empty:\n",
        "            applied_jobs = ratings[ratings['user'] == user_id]['item'].unique()\n",
        "        else:\n",
        "            # Try to extract from the applicants field in jobs_df\n",
        "            applied_jobs = []\n",
        "            for _, job in self.jobs_df.iterrows():\n",
        "                if pd.notna(job.get('applicants')):\n",
        "                    try:\n",
        "                        applicants = job['applicants']\n",
        "                        if isinstance(applicants, str):\n",
        "                            try:\n",
        "                                applicants = json.loads(applicants)\n",
        "                            except:\n",
        "                                # If JSON parsing fails, try to check if user_id is in the string\n",
        "                                if str(user_id) in applicants:\n",
        "                                    applied_jobs.append(job[self.id_col])\n",
        "                                continue\n",
        "\n",
        "                        # Check if user_id is in applicants list or dict\n",
        "                        if isinstance(applicants, list) and str(user_id) in [str(a) for a in applicants]:\n",
        "                            applied_jobs.append(job[self.id_col])\n",
        "                        elif isinstance(applicants, dict) and str(user_id) in applicants:\n",
        "                            applied_jobs.append(job[self.id_col])\n",
        "                    except Exception as e:\n",
        "                        print(f'Error processing applicants for job {job[self.id_col]}: {e}')\n",
        "\n",
        "        if not applied_jobs:\n",
        "            return pd.DataFrame(columns = ['user', 'item', 'score', 'rank'])\n",
        "\n",
        "        # Get all similar jobs for the applied jobs\n",
        "        all_recommendations = []\n",
        "        for job_id in applied_jobs:\n",
        "            try:\n",
        "                similar_jobs = self.get_similar_jobs(job_id, n = 20)  # Get more than needed\n",
        "                all_recommendations.extend(similar_jobs)\n",
        "            except Exception as e:\n",
        "                print(f'Error getting similar jobs for {job_id}: {e}')\n",
        "\n",
        "        # Remove duplicates and already applied jobs\n",
        "        unique_recs = {}\n",
        "        for rec in all_recommendations:\n",
        "            job_id = rec[self.id_col]\n",
        "            if job_id not in applied_jobs and (job_id not in unique_recs or rec['similarity_score'] > unique_recs[job_id]['similarity_score']):\n",
        "                unique_recs[job_id] = rec\n",
        "\n",
        "        # Sort by similarity score and take top N\n",
        "        sorted_recs = sorted(unique_recs.values(), key = lambda x: x['similarity_score'], reverse = True)[:n]\n",
        "\n",
        "        # Format for LensKit\n",
        "        results = []\n",
        "        for i, rec in enumerate(sorted_recs):\n",
        "            results.append({\n",
        "                'user': user_id,\n",
        "                'item': rec[self.id_col],\n",
        "                'score': rec['similarity_score'],\n",
        "                'rank': i + 1\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhlxzGtJdypO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_job_info(job):\n",
        "    '''Format job information for display'''\n",
        "    job_title = job.get('job_title', job.get('job_name', 'Untitled Job'))\n",
        "    company = job.get('company_name', 'Unknown Company')\n",
        "    similarity = job.get('similarity_score', 0)\n",
        "\n",
        "    info = f\"- {job_title} at {company} (ID: {job['job_id']})\"\n",
        "    info += f'\\n  Similarity Score: {similarity:.4f}'\n",
        "\n",
        "    # Add more relevant job info\n",
        "    if 'job_industry' in job and pd.notna(job['job_industry']):\n",
        "        info += f\"\\n  Industry: {job['job_industry']}\"\n",
        "\n",
        "    if 'location' in job and pd.notna(job['location']):\n",
        "        info += f\"\\n  Location: {job['location']}\"\n",
        "\n",
        "    if 'legal_benefits' in job and pd.notna(job['legal_benefits']):\n",
        "        info += f\"\\n  Benefits: {job['legal_benefits']}\"\n",
        "\n",
        "    return info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlHVPwTMd1kc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    print('Initialising job recommender system...')\n",
        "\n",
        "    # Check if DataFrame is loaded successfully\n",
        "    if jobs_df.empty:\n",
        "        print('Error: No job data was loaded from Supabase.')\n",
        "        return\n",
        "\n",
        "    print(f'Loaded {len(jobs_df)} jobs from database.')\n",
        "\n",
        "    # Initialise and train the recommender\n",
        "    recommender = ContentBasedJobRecommender()\n",
        "    recommender.fit(jobs_df)\n",
        "    print('Recommender system trained successfully.')\n",
        "\n",
        "\n",
        "\n",
        "    # Example 1: Get similar jobs to a specific job\n",
        "    sample_job_id = jobs_df.iloc[0]['job_id']  # Get the first job ID as a sample\n",
        "    print(f'\\nFinding similar jobs to job ID: {sample_job_id}')\n",
        "\n",
        "    similar_jobs = recommender.get_similar_jobs(sample_job_id, n = 3)\n",
        "    print(f'Top 3 similar jobs to {sample_job_id}:')\n",
        "    for job in similar_jobs:\n",
        "        print(format_job_info(job) + '\\n')\n",
        "\n",
        "    # Example 2: Create a test user ID and add them as an applicant to a job\n",
        "    print('\\nSimulating a user applying to a job...')\n",
        "    test_user_id = 'test_user_123'\n",
        "\n",
        "    # This is just for testing - in a real app, you'd use actual applicant data\n",
        "    print('Generating recommendations for a test user who applied to job:', sample_job_id)\n",
        "\n",
        "    # Create a test ratings DataFrame to simulate the user having applied to this job\n",
        "    test_ratings = pd.DataFrame({\n",
        "        'user': [test_user_id],\n",
        "        'item': [sample_job_id],\n",
        "        'rating': [1.0]\n",
        "    })\n",
        "\n",
        "    # Get recommendations for this test user\n",
        "    recommendations = recommender.recommend(test_user_id, n = 3, ratings = test_ratings)\n",
        "\n",
        "    if recommendations.empty:\n",
        "        print('No recommendations found for test user.')\n",
        "    else:\n",
        "        print(f'Top 3 job recommendations for test user:')\n",
        "        for _, rec in recommendations.iterrows():\n",
        "            job_id = rec['item']\n",
        "            job = jobs_df[jobs_df['job_id'] == job_id].iloc[0].to_dict()\n",
        "            job['similarity_score'] = rec['score']\n",
        "            print(format_job_info(job) + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kchnufied5HS",
        "outputId": "ecbfe9b7-5e3a-4146-b118-78adca3be092"
      },
      "outputs": [],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npgM_lRQlh9-"
      },
      "source": [
        "---\n",
        "\n",
        "# scikit-learn alternative\n",
        "Not tested yet\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdjv1L40f7_B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import supabase\n",
        "\n",
        "# Define a content-based recommender without using LensKit\n",
        "class ContentBasedJobRecommender:\n",
        "    '''\n",
        "    Content-based job recommender using TF-IDF and cosine similarity\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.jobs_df = None\n",
        "        self.tfidf_matrix = None\n",
        "        self.feature_columns = [\n",
        "            'job_industry',\n",
        "            'industry',\n",
        "            'primary_category',\n",
        "            'job_title',\n",
        "            'job_description',\n",
        "            'job_category',\n",
        "            'location',\n",
        "            'skills',\n",
        "            'tools'\n",
        "        ]\n",
        "        self.id_col = 'job_id'\n",
        "\n",
        "    def fit(self, jobs_df):\n",
        "        '''\n",
        "        Train the recommender on the provided jobs dataframe\n",
        "        '''\n",
        "        self.jobs_df = jobs_df.copy()\n",
        "\n",
        "        # Create a combined text field for TF-IDF\n",
        "        self.jobs_df['combined_features'] = self.jobs_df.apply(self._combine_features, axis=1)\n",
        "\n",
        "        # Create TF-IDF matrix\n",
        "        tfidf = TfidfVectorizer(stop_words='english')\n",
        "        self.tfidf_matrix = tfidf.fit_transform(self.jobs_df['combined_features'].fillna(''))\n",
        "\n",
        "        # Store cosine similarity matrix for faster recommendations\n",
        "        self.cosine_sim = cosine_similarity(self.tfidf_matrix, self.tfidf_matrix)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _combine_features(self, row):\n",
        "        '''\n",
        "        Combine relevant features into a single string for text processing\n",
        "        '''\n",
        "        combined = ''\n",
        "        for col in self.feature_columns:\n",
        "            if col in row and pd.notna(row[col]):\n",
        "                if isinstance(row[col], str):\n",
        "                    combined += row[col] + ' '\n",
        "                elif isinstance(row[col], dict) or isinstance(row[col], list):\n",
        "                    # Handle JSON fields\n",
        "                    try:\n",
        "                        if isinstance(row[col], str):\n",
        "                            data = json.loads(row[col])\n",
        "                        else:\n",
        "                            data = row[col]\n",
        "\n",
        "                        if isinstance(data, dict):\n",
        "                            combined += ' '.join([str(v) for v in data.values() if v]) + ' '\n",
        "                        elif isinstance(data, list):\n",
        "                            combined += ' '.join([str(item) for item in data if item]) + ' '\n",
        "                    except:\n",
        "                        pass\n",
        "        return combined\n",
        "\n",
        "    def get_similar_jobs(self, job_id, n = 10):\n",
        "        '''\n",
        "        Get n most similar jobs to the given job_id\n",
        "        '''\n",
        "        if self.jobs_df is None or self.tfidf_matrix is None:\n",
        "            raise ValueError('Recommender has not been trained yet')\n",
        "\n",
        "        # Find the index of the job in our dataframe\n",
        "        idx = self.jobs_df.index[self.jobs_df[self.id_col] == job_id].tolist()\n",
        "        if not idx:\n",
        "            return []\n",
        "        idx = idx[0]\n",
        "\n",
        "        # Get similarity scores\n",
        "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
        "        sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Remove the job itself\n",
        "        sim_scores = [s for s in sim_scores if s[0] != idx]\n",
        "\n",
        "        # Get top N similar jobs\n",
        "        sim_scores = sim_scores[:n]\n",
        "        job_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "        # Return the similar jobs with their similarity scores\n",
        "        result = []\n",
        "        for i, score in enumerate(sim_scores):\n",
        "            job_idx = job_indices[i]\n",
        "            job_data = self.jobs_df.iloc[job_idx].to_dict()\n",
        "            job_data['similarity_score'] = score[1]\n",
        "            result.append(job_data)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def recommend_for_user(self, user_id, n = 10):\n",
        "        '''\n",
        "        Recommend jobs to a user based on their application history\n",
        "        '''\n",
        "        if self.jobs_df is None or self.tfidf_matrix is None:\n",
        "            raise ValueError('Recommender has not been trained yet')\n",
        "\n",
        "        # Find jobs this user has applied to\n",
        "        applied_jobs = []\n",
        "        for _, job in self.jobs_df.iterrows():\n",
        "            if pd.notna(job.get('applicants')):\n",
        "                try:\n",
        "                    applicants = json.loads(job['applicants']) if isinstance(job['applicants'], str) else job['applicants']\n",
        "                    if isinstance(applicants, list) and str(user_id) in applicants:\n",
        "                        applied_jobs.append(job[self.id_col])\n",
        "                    elif isinstance(applicants, dict) and str(user_id) in applicants:\n",
        "                        applied_jobs.append(job[self.id_col])\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        if not applied_jobs:\n",
        "            return []\n",
        "\n",
        "        # Get all similar jobs for the applied jobs\n",
        "        all_recommendations = []\n",
        "        for job_id in applied_jobs:\n",
        "            similar_jobs = self.get_similar_jobs(job_id, n=20)  # Get more than needed\n",
        "            all_recommendations.extend(similar_jobs)\n",
        "\n",
        "        # Remove duplicates and already applied jobs\n",
        "        unique_recs = {}\n",
        "        for rec in all_recommendations:\n",
        "            job_id = rec[self.id_col]\n",
        "            if job_id not in applied_jobs and (job_id not in unique_recs or rec['similarity_score'] > unique_recs[job_id]['similarity_score']):\n",
        "                unique_recs[job_id] = rec\n",
        "\n",
        "        # Sort by similarity score and take top N\n",
        "        sorted_recs = sorted(unique_recs.values(), key=lambda x: x['similarity_score'], reverse=True)[:n]\n",
        "\n",
        "        return sorted_recs\n",
        "\n",
        "# Example usage function\n",
        "def main():\n",
        "    # Load environment variables\n",
        "    load_dotenv()\n",
        "\n",
        "    # Initialize Supabase client\n",
        "    supabase_url = os.getenv('SUPABASE_URL')\n",
        "    supabase_key = os.getenv('SUPABASE_KEY')\n",
        "\n",
        "    if not supabase_url or not supabase_key:\n",
        "        print('Error: Supabase credentials not found in environment variables')\n",
        "        return\n",
        "\n",
        "    supabase_client = supabase.create_client(supabase_url, supabase_key)\n",
        "\n",
        "    # Fetch jobs data from Supabase\n",
        "    try:\n",
        "        response = supabase_client.table('jobs').select('*').execute()\n",
        "        jobs_data = response.data\n",
        "\n",
        "        if not jobs_data:\n",
        "            print('No jobs data found')\n",
        "            return\n",
        "\n",
        "        jobs_df = pd.DataFrame(jobs_data)\n",
        "\n",
        "        # Initialise and train the recommender\n",
        "        recommender = ContentBasedJobRecommender()\n",
        "        recommender.fit(jobs_df)\n",
        "\n",
        "        # Test with a sample user ID\n",
        "        user_id = 'user123'  # Replace with an actual user ID from your data\n",
        "        recommendations = recommender.recommend_for_user(user_id, n = 5)\n",
        "\n",
        "        print(f'Top 5 job recommendations for user {user_id}:')\n",
        "        for i, job in enumerate(recommendations):\n",
        "            print(f\"{i+1}. {job.get('job_title', 'Unknown')} - {job.get('company_name', 'Unknown')}\")\n",
        "            print(f\"   Similarity Score: {job['similarity_score']:.4f}\")\n",
        "            print(f\"   Description: {job.get('job_description', '')[:100]}...\")\n",
        "            print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
